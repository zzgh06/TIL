# 3.1 운영체제와 컴퓨터

## 3.1.1 운영체제의 역할과 구조

    운영체제의 역할
      1. CPU 스케줄링과 프로세스 관리 : CPU 소유권을 어떤 프로세스에 할당할지, 프로세스의 생성과 삭제, 자원 할당 및 반환을 관리
      2. 메모리 관리 : 한정된 메모리를 어떤 프로세스에 얼마큼 할당해야 하는지 관리
      3. 디스크 파일 관리 : 디스크 파일을 어떠한 방법으로 보관할지 관리
      4. I/O 디바이스 관리 : I/O 디바이스들인 마우스, 키보드와 컴퓨터 간에 데이터를 주고받는 것을 관리

    운영체제의 구조
      운영체제의 구조는 다음과 같다
      - 유저 프로그램
      - GUI
      - 시스템콜
      - 커널
      - 드라이버
      - 하드웨어
      이중 GUI, 시스템콜, 커널, 드라이버 부분이 운영체제를 지칭한다, 참고로 GUI가 없고 CUI만 있는 리눅스 서버도 있다

      용어
      - GUI : 사용자가 전자장치와 상호작용할 수 있도록 하는 사용자 인터페이스의 한 형태, 아이콘을 마우스로 클릭하는 단순한 동작으로 상호 작용할 수 있도록 해준다
      - 드라이버 : 하드웨어를 제어하기 위한 소프트웨어
      - CUI : 그래픽이 아닌 명령어로 처리하는 인터페이스

      시스템콜
        - 운영체제가 커널에 접근하기 위한 인터페이스, 커널 함수를 호출할 떄 사용
        - 유저 프로그램이 I/O 요청으로 트랩(trap)을 발동하면 올바른 I/O 요청인지 확인한 후 유저 모드가 시스템콜을 통해 커널 모드로 변환되어 실행
        - 예를 들어 I/O 요청인 fs.readFile()이라는 파일 시스템의 파일을 읽는 함수가 발생하였을때, 유저 모드에서 파일 읽지 않고 커널 모드로 들어가 파일을 읽고 다시 유저모드로 돌아가 그 뒤에 있는 유저 프로그램의 로직을 수행
        - 이 과정을 통해 컴퓨터 자원에 대한 직접 접근을 차단할 수 있고 프로그램을 다른 프로그램으로부터 보호할 수 있다
        - 프로세스나 스레드에서 운영체제로 어떠한 요청을 할 때 시스템콜이라는 인터페이스와 커널을 거쳐 운영체제에 전달
        - 시스템콜은 하나의 추상화 계층, 이를 통해 네트워크 통신이나 데이터베이스와 같은 낮은 단계의 영역 처리에 대한 부분을 많이 신경 쓰지 않고 프로그램을 구현할 수 있는 장점이 있다

        modebit
          - 시스템콜이 작동될 때 modebit을 참고해서 유저 모드와 커널 모드를 구분
          - 1(유저 모드) 또는 0(커널 모드)의 값을 가지는 플래그 변수
          - 유저 프로그램이 카메라를 이용하려고 할 때 시스템콜을 호출하고 modebit을 1에서 0으로 바꾸며 커널 모드로 변경한 후 카메라 자원을 이용한 로직을 수행, 그 이후에 modebit을 0에서 1로 바꿔서 유저 모드로 변경하고 이후 로직을 수행

      용어
      - I/O 요청 : 입출력 함수, 데이터베이스, 네트워크, 파일 접근 등
      - 유저모드 : 유저가 접근할 수 있는 영역을 제한적으로 두며 컴퓨터 자원에 함부로 침범하지 못하는 모드
      - 커널모드 : 모든 컴퓨터 자원에 접근할 수 있는 모드
      - 커널 : 운영체제의 핵심 부분이자 시스템콜 인터페이스를 제공, 보안, 메모리, 프로세스, 파일 시스템, I/O 디바이스, I/O 요청 관리 등 운영체제의 중추적인 역할


## 3.1.2 컴퓨터의 요소

    컴퓨터는 CPU, DMA 컨트롤러, 메모리, 타이머, 디바이스 컨트롤러 등으로 이루어져 있다

    CPU(Central Processing Unit)
      - 산술논리연산장치, 제어장치, 레지스터로 구성되어 있는 컴퓨터 장치
      - 인터럽트에 의해 단순히 메모리에 존재하는 명령어를 해석해서 실행
    
      제어장치(CU, Control Unit)
        - 프로세스 조작을 지시하는 CPU의 한 부품
        - 입출력장치 간 통신을 제어라고 명령어들을 읽고 해석하며 데이터 처리를 위한 순서를 결정

      레지스터
        - CPU 안에 있는 매우 빠른 임시기억장치
        - CPU와 직접 연결되어 있어 연산 속도가 메모리보다 수십 배에서 수백 배까지 빠르다
        - CPU는 자제적으로 데이터를 저장할 방법이 없기 때문에 레지스트러를 거쳐 데이터를 전달

      산술논리연산장치(ALU, Arithmetic Logic Unit)
        - 덧셈, 뺄셈 같은 두 숫자의 산술 연산과 배타적 논리합, 논리곱 같은 논리 연산을 계산하는 디지털 회로

        CPU의 연산처리
        1) 제어장치가 메모리에 게산할 값을 로드. 또한, 레지스트에도 로드
        2) 제어장치가 레지스터에 있는 값을 계산하라고 산술논리연산장치에 명령
        3) 제어장치가 계산된 값을 다시 '레지스터에서 메모리로' 계산한 값을 저장

      인터럽트
        - 어떤 신호가 들어왔을 때 CPU를 잠깐 정지시키는 것
        - IO 디바이스로 인한 인터럽트, 0으로 숫자를 나누는 산술 연산에서의 인터럽트, 프로세스 오류 등으로 발생
        - 인터럽트 핸들러 함수가 모여 있는 인터업트 벡터로 가서 인터럽트 핸들러 함수가 실행
        - 인터럽트 간에는 우선순위가 있고 우선순위에 따라 실행
        
        하드웨어 인터럽트
          - 키보드를 연결하거나 마우스를 연결하는 일 등의 IO 디바이스에 의한 인터럽트
          - 인터럽트 라인이 설계된 이후 순차적인 인터럽트 실행을 중지하고 운영체제에 시스템콜을 요청해서 원하는 디바이스로 향해 디바이스에 있는 작은 로컬 버퍼에 접근하여 일을 수행

        소프트웨어 인터럽트
          - 소프트웨어 인터럽트는 트랩이라고도 하며, 프로세스 오류 등으로 프로세스가 시스템콜을 호출할 때 발동

        용어
        - 인터럽트 핸들러 함수 : 인터럽트가 발생했을 때 이를 핸들링하기 위한 함수, 커널 내부의 IRQ를 통해 호출되며 request_irq()를 통해 인터럽트 핸들러 함수를 등록할 수 있다
        

    DMA 컨트롤러
      - I/O 디바이스가 메모리에 직접 접근할 수 있도록하는 하드웨어 장치
      - CPU에만 너무 많은 인터럽트 요청이 들어오기 때문에 CPU의 부하를 막아주며 일을 부담하는 보조 일꾼
      - 또한, 하나의 작업을 CPU와 DMA 컨트롤러가 동시에 하는 것을 방지
    
    메모리
      - 전자회로에서 데이터나 상태, 명령어 등을 기록하는 장치
      - 보통 RAM(Random Access Memory)을 일컬어 메모리라고도 한다
      - CPU는 계산을 담당하고 메모리는 기억을 담당
      - 메모리가 클스록 많은 일을 동시에 할 수 있다

    타이머
      - 몇 초 안에는 작업이 끝나야 한다는 것을 정하고 특정 프로그램에 시간제한을 다는 역할
      - 시간이 많이 걸리는 프로그램이 작동할 때 제한을 걸기 위해 존재

    디바이스 컨트롤러
      - 컴퓨터와 연결되어 있는 IO 디바이스들의 작은 CPU를 말하고 옆에 붙어 있는 로컬 버퍼는 각 디바이스에서 데이터를 임시로 저장하기 위한 작은 메모리를 뜻한다


# 3.2 메모리

## 3.2.1 메모리 계층

    - 메모리 계층은 레지스터, 캐시, 메모리, 저장장치로 구성되어 있다
      - 레지스터 : CPU 안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적다
      - 캐시 : L1, L2 캐시를 지칭, 휘발성, 속도 빠름, 기억 용량이 적다
      - 주기억장치 : RAM을 가리킨다, 휘발성, 속도 보통, 기억 용량이 보통
      - 보조기억장치 : HDD, SSD를 일컬으며 비휘발성, 속도 낮음, 기억 용량이 많다

    - 램은 하드디스크로부터 일정량의 데이터를 복사해서 임시 저장하고 이를 필요 시마다 CPU에 빠르게 전달하는 역할을 한다
    - 계층이 있는 이유는 경제성과 캐시 때문이다 

    캐시
      - 데이터를 미리 복사해 놓은 임시 저장소
      - 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
      - 이를 통해 데이터를 접근하는 시간이 오래 걸리는 경우를 해결하고 무언가를 다시 계산하는 시간을 절약할 수 있다
      - 실제로 메모리와 CPU 사이의 속도 차이가 너무 크기 때문에 그 중간에 레지스터 계층을 둬서 속도 차이를 해결, 이렇게 속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층을 캐싱 계층이라고 한다

      지역성의 원리
        - 캐시 계층을 두는 것 말고 캐시를 직접 설정할 때는 자주 사용하는 데이터를 기반으로 설정해야한다
        - 자주 사용하는 데이터에 대한 근거는 지역성으로 지역성은 시간 지역성과 공간 지역성으로 나뉜다

          시간 지역성 : 최근 사용한 데이터에 다시 접근하려는 특성
          공간 지역성 : 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성

    캐시히트와 캐시미스
      - 캐시에서 원하는 데이터를 찾았다면 캐시히트
      - 해당 데이터가 캐시에 없다면 두메모리로 가서 데이터를 찾아오는 것을 캐시미스
      - 캐시히트를 하게 되면 해당 데이터를 제어장치를 거쳐 가져오게 되는데, 캐시히트의 경우 위치가 가깝고 CPU 내부 버스를 기반으로 작동하기 때문에 빠르다
      - 반면에 캐시미스가 발생되면 메모리에서 가져오게 되는데, 이는 시스템 버스를 기반으로 작동하기 때문에 느리다

      캐시매핑
        - 캐시가 히트되기 위해 매핑하는 방법
        - CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고받을 때를 기반으로 설명
          - 직접 매핑 : 메모리가 1~100이 있고 캐시가 1~10이 있다면 1:1~10, 2:1~20... 이런 식으로 매핑하는 것을 말한다, 처리는 빠르지만 충동이 잦다
          - 연관 매핑 : 순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑한다. 충돌은 적지만 모든 블록을 탐색해야 해서 속도가 느리다
          - 직접 연관 매핑 : 직접 매핑과 연관 매핑을 합쳐 놓은 것으로 순서는 일치시키지만 집합을 둬서 저장하며 블록화되어 있기 때문에 검색은 더 효율적

      웹 브라우저의 캐싱
        - 쿠키, 로컬 스토리지, 세션 스토리지
        - 사용자의 커스텀한 정보나 인증 모듈 관련 사항들을 웹 브라우저에 저장해서 추후 서버에 요청할 때 자신을 나타내는 아이덴티티나 중복 요청 방지를 위해 사용

        쿠키
          - 만료기한이 있는 키-값 저장소
          - same site 옵션을 strict로 설정하지 않았을 경우 다른 도메인에서 요청했을 때 자동 전송
          - 4KB까지 데이터를 저장할 수 있고 만료기한을 정할 수 있다
          - 쿠키를 설정할 때는 document.cookie로 쿠키를 볼 수 없게 httponly 옵션을 거는 것이 중요
          - 클라이언트 또는 서버에서 만료기한 등을 정할 수 있는데 보통 서버에서 만료기한을 정한다

        로컬 스토리지
          - 만료기한이 없는 키-값 저장소
          - 10MB까지 저장
          - 웹 브라우저를 닫아도 유지되고 도메인 단위로 저장, 생성
          - HTML5를 지원하지 않는 웹 브라우저에서는 사용할 수 없으며 클라이언트에서만 수정 가능

        세션 스토리지
          - 만료기한이 없는 키-값 저장소
          - 탭 단위로 세션 스토리지를 생성, 탭을 닫을 때 해당 데이터가 삭제
          - 5MB까지 저장이 가능
          - HTML5를 지원하지 않는 웹 브라우저에서는 사용할 수 없으며 클라이언트에서만 수정 가능

      데이터베이스의 캐싱 계층
        - 데이터베이스 시스템을 구축할 때도 메인 데이터베이스 위에 레디스(redis) 데이터베이스 계층을 '캐싱 계층'으로 둬서 성능을 향상시키기도 한다


## 3.2.2 메모리 관리

    가상 메모리
      - 메모리 관리 기법의 하나로 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것
      - 이때 가상적으로 주어진 주소를 가상 주소라고 하며, 실제 메모리상에 있는 주소를 실제 주소라고 한다
      - 가상 주소는 메모리관리장치(MMU)에 의해 실제 주소로 변환되며, 이 덕분에 실제 주소를 의식할 필요 없이 프로그램을 구축할 수 있게 된다
      - 가상 메모리는 가상 주소와 실제 주소가 매핑되어 있고 프로세스의 주소 정보가 들어 있는 '페이지 테이블'로 관리, 이때 속도 향상을 위해 TLB를 쓴다

      스와핑
        - 만약 가상 메모리에는 존재하지만 실제 메모리인 RAM에는 현재 없는 데이터나 코드에 접근할 경우 페이지 폴트가 발생
        - 이때 메모리에서 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크의 일부분을 마치 메모리처럼 불러와 쓰는 것을 스와핑이라고 한다
        - 이를 통해 마치 페이지 폴트가 일어나지 않은 것처럼 만든다

      페이지 폴트
        - 프로세스의 주소 공간에는 존재하지만 지금 이 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우에 발생
        - 페이지 폴트와 그로 인한 스와핑은 다음 과정으로 이루어진다
          1. CPU는 물리 메모리를 확인하여 해당 페이지가 없으면 트랩을 발생해서 운영체제에 알린다
          2. 운영체제는 CPU의 동작을 잠시 멈춘다
          3. 운영체제는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 확인하고, 없으면 프로세스를 중단하고 현재 물리 메로리에 비어 있는 프레임이 있는지 찾는다. 물리 메모리에도 없다면 스와핑이 발동
          4. 비어 있는 프레임에 해당 페이지를 로드하고, 페이지 테이블을 최신화
          5. 중단되었던 CPU를 다시 시작한다

    용어
    TLB : 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시. 페이지 테이블에 있는 리스트를 보관하며 CPU가 페이지 테이블까지 가지 않도록 해 속도를 향상시킬 수 있는 캐시 계층이다
    페이지 : 가상 메모리를 사용하는 최소 크기 단위
    프레임 : 실제 메모리를 사용하는 최소 크기 단위

    스레싱
      - 메모리의 페이지 폴트율이 높은 것을 의미, 이는 컴퓨터의 심각한 성능 저하를 초래
      - 메모리에 너무 많은 프로세스가 동시에 올라가게 되면 스와핑이 많이 일어나서 발생
      - 페이지 폴트가 일어나면 CPU 이용률이 낮아지는데 운영체제는 "CPU가 한가한가?"라고 생각하여 가용성을 더 높이기 위해 더 많은 프로세스를 메모리에 올리게 된다
      - 이와 같은 악순환이 반복되며 스레싱이 일어나게된다
      - 이를 해결하기 위한 방법으로는 메모리를 늘리거나, HDD를 사용한다면 HDD를 SDD로 바꾸는 방법이 있으며 이외에 운영체제에서 이를 해결할 수 있는 방법은 작업 세트와 PFF가 있더

      작업 세트
        - 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 것
        - 미리 메모리에 로드하면 탐색에 드는 비뵹을 줄일 수 있고 스와핑 또한 줄일 수 있다

      PFF
        - 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법
        - 만약 상한선에 도달한다면 프레임을 늘리고 하한선에 도달한다면 프레임을 줄인다

    메모리 할당
      - 메모리에 프로그램을 할당할 때는 시작 메모리 위치, 메모리의 할당 크기를 기반으로 할당하는데, 연속 할당과 불연속 할당으로 나뉜다

      연속 할당
        - 메모리에 '연속적으로' 공간을 할당하는 것
        - 메모리를 미리 나누어 관리하는 고정 분할 방식과 매 시점 프로그램의 크기에 맞게 메모리를 분할하여 사용하는 가변 분할 방식이 있다

        고정 분할 방식
          - 메모리를 미리 나누어 관리하는 방식
          - 메모리가 미리 나뉘어 있기 때문에 융통성이 없으며 내부 단편화가 발생

        가변 분할 방싣
          - 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용
          - 외부 단편화가 발생할 수 있다
          - 이는 최초적합, 최적적합, 최악적합이 있다

            - 최초적합 : 위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당
            - 최적적합 : 프로세스의 크기 이상인 공간 중 가장 작은 홀부터 할당
            - 최악적합 : 프로세스의 크기와 가장 차이가 나는 홀에 할당

      용어
      내부 단편화 : 메모리를 나눈 크기보다 프로그램이 작아서 들어가지 못하는 공간이 많이 발생하는 현상
      외부 단편화 : 메모리를 나눈 크기보다 프로그램이 커서 들어가지 못하는 공간이 많이 발생하는 현상
      홀 : 할당할 수 있는 비어 있는 메모리 공간

      불연속 할당
        - 현대 운영체제가 쓰는 방법으로 불연속 할당인 페이징 기법이 있다
        - 메모리를 동일한 크기의 페이지(보통 4KB)로 나누고 프로그램마다 페이지 테이블을 두어 이를 통해 메모리에 프로그램을 할당
        - 페이징 기법 말고도 세그멘테이션, 페이지드 세그멘테이션이 있다

        페이징
          - 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당
          - 홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환이 복잡해진다

        세그멘테이션
          - 페이지 단위가 아닌 의미 단위인 세그먼트로 나누는 방식
          - 코드와 데이터로 나누거나 코드 내의 작은 함수를 세그먼트로 놓고 나눌 수 있다
          - 이는 공유와 보안 측면에서 장점을 가지지만 홀 크기가 균일하지 않은 단점도 있다

        페이지드 세그멘테이션
          - 프로그램을 의미 단위인 세그먼트로 나눠 공유나 보안 측면에 강점을 두고 임의의 길이가 아닌 동일한 크기의 페이지 단위로 나누는 것

      페이지 교체 알고리즘
        - 메모리는 한정되어 있기 때문에 스와핑이 많이 일어난다, 스와핑은 많이 일어나지 않도록 설계되어야 하며 이는 페이지 교체 알고리즘을 기반으로 스와핑이 일어난다

        오프라인 알고리즘
          - 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘
          - 사용할 수 없는 알고리즘이만 다른 알고리즘과의 선능 비교에 대한 상한기준을 제공

        FIFO(First In First Out)
          - 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓은 방법   
      
        LRU(Least Recently Used)
          - 참조가 가장 오래된 페이지를 바꾼다
          - 오래된 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야 하는 문제점이 있다
          - LRU 구현을 프로그래밍으로 구현할 때는 보통 두 개의 자료 구조로 구현하는데 바로 해시 테이블과 이중 연결 리스트이다
          - 해시 테이블은 이중 연결 리스트에서 빠르게 찾을 수 있도록 사용, 이중 연결리스트는 한정된 메모리를 나타낸다

        NUR(Not Used Recently)
          - LRU에서 발전한 알고리즘으로 일명 clock 알고리즘이라고 한다
          - 먼저 0과 1을 가진 비트를 두고, 1은 최근에 참조되었고 0은 참조되지 않았음을 의미
          - 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고, 해당 부분을 1로 바꾸는 알고리즘

        LFU(Least Frequently Used)
          - 가장 참조 횟수가 적은 페이지를 교체한다. 즉, 많이 사용되지 않은 것을 교체하는 것 