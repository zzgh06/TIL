# 2.1 네트워크의 기초

    네트워크
    - 컴퓨터 등의 장치들이 통신 기술을 이용하여 구축하는 연결망
    - 노드(서버, 라우터, 스위티 등 네트워크 장치)와 링크(유•무선)가 서로 연결되어 리소스를 공유하는 집합


## 2.1.1 처리량과 지연시간

    좋은 네트워크의 기준
    - 많은 처리량을 처리할 수 있으며 지연 시간이 짧고 장애 빈도가 적으며 좋은 보안을 갖춘 네트워크

### 처리량

    - 처리량은 링크 내애서 성공적으로 전달된 데이터의 양, 보통 얼만큼의 트랙픽을 처리했는지를 나타낸다(많은 트래픽을 처리한다 = 많은 처리량을 가진다)
    - 단위 bps(bits per second) : 초당 전송 또는 수신되는 비트 수
    - 트래픽(데이터의 양), 네트워크 장치 간의 대역폭, 네트워크 중간에 발생하는 에러, 장치의 하드웨어 스펙에 영향을 받는다

    용어
    - 대역폭 : 주어진 시간동안 네트워크 연결을 통해 흐를 수 있는 최대 비트 수

### 지연 시간

    - 어떤 메시지가 두 장치 사이를 왕복하는데 걸린 시간
    - 매체 타입(무선, 유선), 패킷(=네트워크가 전달하는 데이터의 형식화된 블록) 크기, 라우터의 패킷 처리 시간에 영향을 받는다


## 2.1.2 네트워크 토폴리지와 병목현상

### 네트워크 토폴리지

    - 노드와 링크가 어떻게 배치되어 있는지에 대한 방식이자 연결 형태

    1) 트리 토폴리지(=계층형 토폴리지)
        - 트리 형태로 배치한 네트워크 구성
        - 노드의 추가, 삭제가 쉬우며 특정 노드에 트래픽이 집중될 때 하위 노드에 영향을 끼칠 수 있다.
    
    2) 버스 토폴리지
        - 중앙 통신 회신 하나에 여러 개의 노드가 연결되어 공유하는 네트워크 구성
        - 근거리 통신망(LAN)에서 사용
        - 설치 비용이 적고 신뢰성이 우수, 노드를 추가하거나 삭제하기 편리
        - 스푸닝이 가능한 문제가 있음
            
            * 스푸닝 : 송신부의 패킷을 송신과 관련 없는 다른 호스트에 가지 않도록 하는 스위칭 기능을 마비시키거나 속여 특정 노드에 해당 패킷이 오도록 처리하는 것

    3) 스타 토폴리지
        - 중앙에 있는 노드에 모두 연결된 네트워크 구성
        - 노드를 추가하거나 에러를 탐지하기 쉽고 패킷의 충돌 발생 가능성이 적다
        - 노드애 장애가 발생해도 쉽게 에러를 발견할 수 있으며 장애 노드가 중앙 노드가 아닐 경우 다른 노드에 영향을 끼치는 것이 적다
        - 하지만 중앙 노드에 장애가 발생하면 전체 네트워크를 사용할 수 없고 설치 비용이 고가

    4) 링형 토폴리지
        - 각각의 노드가 양 옆의 두 노드와 연결하여 전체적으로 고리처럼 하나의 연속된 길을 통해 통신을 하는 망 구성 방식
        - 데이터는 노드에서 노드로 이동을 하게 되며, 각각의 노드는 고리 모양의 길을 통해 패킷을 전달
        - 노드 수가 증가되어도 네트워크상의 손실이 거의 없고 충돌 방생 가능성이 적으며 노드의 고장발견이 쉽게 찾을 수 있다
        - 하지만 네트워크 구성이 어렵고 회선에 장애가 발생하면 전체 네트워크에 영향을 크게 끼친다

    5) 메시 토폴로지
        - 망형 토폴로지라고도 하며 그물망처럼 연결되어 있는 구조
        - 한 단말 장치에 장애가 발생해도 여러 개의 경로가 존재하므로 네트워크를 계속 사용할 수 있고 트래픽도 분산처리가 가능
        - 하지만 노드의 추가가 어렵고 구축비용과 운용비용이 고가

### 병목현상

    - 전체 시스템의 성능이나 용량이 하나의 구성 요소로 인해 제한을 받는 현상
    - 네트워크 구조라고도 일컫는 토폴로지가 중요한 이유는 병목현상을 찾을 때 중요한 기준이 되기 떄문이다.


## 2.1.3 네트워크 분류

    - 네트워크는 규모를 기반으로 분류할 수 있음
        - LAN(Local Area Network) : 사무실과 개인적으로 소유 가능하는 규모
        - MAN(Metropolitan Area Network) : 서울시 등의 정도의 규모
        - WAN(Wide Area Network) : 세계 규모

    1) LAN : 근거리 통신망으로 같은 건물이나 캠퍼스 같은 좁은 공간에서 운영되며 전송속도가 빠르고 혼잡하지 않다
    2) MAN : 대도시 지역 네트워크를 나타내며 도시 같은 넓은 지역에서 운영되며 전송속도는 평균이며 LAN 보다는 혼잡
    3) WAN : 광역 네트워크로 국가 또는 대륙 같은 더 넓은 지역에서 운영 전송속도는 낮고 MAN 보다 혼잡


## 2.1.4 네트워크 성능 분석 명령어

    - ping(Packet INternet Groper)
        - 네트워크 상태를 확인하려는 대상 노드를 향해 일정 크기의 패킷을 전송하는 명령어
        - 이를 통해 해당 노드의 패킷 수신 상태와 도달하기까지 시간, 네트워크가 잘 연결되어 있는지 확인할 수 있다
        - ping 은 TCP/IP 프로토콜 중에 ICMP 프로토콜을 통해 동작하여 ICMP 를 지원하지 않는 기기에서 실행할 수 없다

    - netstat
        - 접속되어 있는 서비스들의 네트워크 상태를 표시하는데 사용되며 네크워크 접속, 라우팅 테이블, 네크워크 프로토콜 등 리스트를 보여준다
        - 주로 서비스 포트가 열려있는지 확인할 때 사용

    - nslookup
        - DNS에 관련된 내용을 확인하기 위해 쓰는 명령어
        - 특정 도메인에 맴핑된 IP를 확인하기 위해 사용

        * DNS 
        - 웹사이트에 접속 할 때 우리는 외우기 어려운 IP 주소 대신 도메인 이름을 사용한다.
        - 도메인 이름을 사용했을 때 입력한 도메인을 실제 네트워크상에서 사용하는 IP 주소로 바꾸고 해당 IP 주소로 접속하는 과정이 필요하다.
        - 이러한 과정, 전체 시스템을 DNS(도메인 네임 시스템)라고 한다.

    - tracert
        - 목적지 노드까지 네트워크 경로를 확인할 때 사용
        - 목적지 노드까지 구간들 중 어느 구간애서 응답시간이 느려지는지 확인

    이외에도 ftp를 통해 대형 파일을 전송하여 테스팅하거나 tcpdump를 통해 노드러 오고 가는 패킷을 캡처하는 명령어가 존재하며 네트워크 분석 프로그램으로는 wireshark, netmon이 있다.


# 2.2 TCP/IP 4계층 모델

    인터넷 프로토콜 스위트는 인터넷에서 컴퓨터들이 서로 정보를 주고받는데 쓰이는 프로토콜의 집합, 이를 TCP/IP 4계층 모델 혹은 OSI 7계층 모델로 설명

## 2.2.1 계층 구조

    - TCP/IP 계층 : 애플리케이션 계층, 전송계층, 인터넷 계층, 링크 계층
    - OSI 계층 : (애플리케이션 계층, 프레젠테이션 계층, 세션 계층), (전송 계층), (네트워크 계층), (데이터 링크 계층, 물리 계층)

    이 계층들은 특정 계층이 변경되었을 때 다른 계층이 영향을 받지 않도록 설계되어 있다.


### 애플리케이션 계층(FTP, HTTP, SSH, SMTP, DNS)

    - FTP, HTTP, SSH, SMTP, DNS 등 응용 프로그램이 사용되는 프로토콜 계층이며 웹 서비스, 이메일 등 서비스를 실질적으로 사람들에게 제공

        - FTP : 장치와 장치 간의 파일을 전송하는데 사용되는 표준 통신 프로토콜
        - SSH : 보안되지 않은 네크워크 서비스를 안전하게 운영하기 위한 암호화 네트워크 프로토콜
        - HTTP : World Wide Web을 위한 데이터 통신의 기초이자 웹 사이트를 이용하는데 쓰는 프로토콜
        - SMTP : 전자 메일 전송을 위한 인터넷 표준 통신 프로토콜
        - DNS : 도메인의 이름과 IP 주소를 맵핑해주는 서버


### 전송 계층(TCP, UDP)

    - 송신자와 수신자를 연결하는 통신 서비스를 제공
    - 연결 지향 데이터 스트림 지원, 신뢰성, 흐름 제어를 제공
    - 애플리케이션과 인터넷 계층 사이의 데이터가 전달될 떄 중계 역할

    - TCP
        - 패킷 사이의 순서를 보장, 연결지향 프로토콜을 사용하여 신뢰성을 구축해서 수신 여부를 확인
        - 가상회선 패킷 교환 방식을 사용

            ▶ 가상회선 패킷 교환 방식
                - 가상회선 패킷 교환 방식은 각 패킷에는 가상회선 식별자가 포함되며 모든 패킷을 전송하면 가상회선이 해제되고 패킷들은 전송된 순서대로 도착하는 방식

    - UTP
        - 순서를 보장하지 않고 수신 여부를 확인하지 않음
        - 단순히 데이터만 주는 '데이터그램 패킷 교환 방식'을 사용

            ▶ 데이터그램 패킷 교환 방식
                - 패킷이 독립적으로 이동하며 최적의 경로를 선택하여 가는데, 하나의 메시지에서 분할된 패킷은 서로 다른 경로로 전송될 수 있고 도착한 순서가 다를 수 있는 방식

    - TCP 연결 성립 과정
        - 3-웨이 핸드셰이크
            1) SYN 단계 : 클라이언트는 서버에 클라이언트의 ISN(초기 네트워크 연결을 할 때 할당된 32비트 고유 시퀀스 번호)를 담아 SYN(연결 요청 플래그)를 보낸다
            2) SYN + ACK 단계 : 서버는 클라이언트의 SYN을 수신하고 서버의 ISN을 보내며 승인번호로 클라이언트의 ISN + 1을 보낸다.
            3) ACK 단계 : 클라이언트는 서버의 ISN + 1한 값인 승인번호를 담아 ACK(응답플래그)를 서버에 보낸다.

                > 이렇게 3-웨이 핸드셰이크 과정 이후 신뢰성이 구축되고 데이터 전송을 시작(참고로 UTP는 이 과정이 없기 때문에 신뢰성이 없는 계층이라 한다)

    - TCP 연결 해제 과정
        TCP가 연결을 해제할 때는 4-웨이 핸드셰이크 과정이 발생
            1) 먼저 클라이언트가 닫으려고 할 때 FIN으로 설정된 세그먼트를 보낸다 그리고 클라이언트는 FIN_WAIT_1 상태로 들어가고 서버의 응답을 기다린다
            2) 서버는 클라이언트로 ACK라는 승인 세그먼트를 보내고 CLOSE_WAIT 상태에 들어간다. 클라이언트가 세그먼트를 받으면 FIN_WAIT_2 상태에 들어간다
            3) 서버는 ACK를 보내고 일정 시간 이후에 클라이언트에 FIN이라는 세그먼트를 보낸다.
            4) 클라이언트는 TIME_WAIT 상태가 되고 다시 서버로 ACK를 보내서 서버는 CLOSED 상태가 된다.
               이후 클라이언트는 어느 정도 시간을 대기한 후 연결이 닫히고 클라이언트와 서버의 모든 자원의 연결이 해제

            * TIME_WAIT : 소켓이 소멸되지 않고 일정 시간 유지되는 상태
                TIME_WAIT 과정에서 일정 시간 뒤에 닫는 이유는
                    - 첫 번째 : 지연 패킷이 발생할 경우를 대비하기 위함, 패킷이 뒤즞게 도달하고 이를 처리하지 못한다면 데이터 무결성(데이터의 정확성과 일관성 유지)의 문제가 발생
                    - 두 번쨰 : 두 장치가 연결이 닫혔는지 확인


### 인터넷 계층(IP, ARP, ICMP)

    - 장치로 부터 받은 네트워크 패킷을 IP 주소로 지정된 목적지로 전송하기 위해 사용되는 계층
    - 패킷을 수신해야 할 상대의 주소를 지정하여 데이터를 전달
    - 상대방이 제대로 받았는지에 대해 보장하지 않는 비연결적인 특징


### 링크 계층(=네트워크 접근 계층)

    - 전선, 광섬유, 무선 등 실질적으로 데이터를 전달하며 장치 간에 신호를 주고받는 '규칙'을 정하는 계층
    - 이를 물리계층과 데이터 링크 계층으로 나누기도 하는데 
        - 물리 계층 : 무선 LAN과 유선 LAN을 통해 0과 1로 이루어진 데이터를 보내는 계층
        - 데이터 링크 계층 : '이더넷 프레임(이더넷 프레임은 데이터 링크 계층 프로토콜 데이터 단위)'을 통해 에러 확인, 흐름 제어, 접근 제어를 담당하는 계층

    - 유선 LAN(IEEE802.3)
        - 전이중화 통신 : 양쪽 장치가 동시에 송수신할 수 있는 방식, 송신로와 수신로로 나눠서 데이터를 주고 받음

    - 유선 LAN을 이루는 케이블
        - 트위스트 페어 케이블(TP 케이블) : 8개의 구리선을 두 개씩 꼬아서 만든 케이블
        - 광섬유 케이블 : 광섬유로 만든 케이블, 레이저를 이용해서 통신하여 장거리 및 고속 통신이 가능

    - 무선 LAN(IEEE802.11)
        - 수신과 송신에 같은 채널을 사용하기 때문에 반이중화 통신을 사용
        - 반이중화 통신 : 양쪽 장치는 서로 통신할 수 있지만 동시에는 통신할 수 없으며 한 번에 한 방향만 통신할 수 있는 방식
            - 장치가 신호를 수신하기 시작하며 전송이 완료될 때까지 기다린 후 응답
            - 둘 이상의 장치가 동시에 전송하면 충돌이 발생할 수 있어 충돌 방지 시스템이 필요

        - CSMA/CA : 반이중화 통신 중 하나로 장치에서 데이터를 보내기 전에 캐리어 감지 등으로 사전에 가능한 한 충돌을 방지하는 방식
            1) 데이터를 송신하기 전에 무선 매체를 살핀다
            2) 캐리어 감지 : 회선이 비어있는지를 판단
            3) IFS(Inter FrameSpace) : 랜덤 값을 기반으로 정해진 시간만큼 기다리며, 만약 무선 매체가 사용 중이면 점차 그 간격을 늘려가며 기다린다
            4) 이후에 데이터를 전송

    - 무선 LAN을 이루는 주파수
        - 무선 신호 전달 방식을 이용하여 2대 이상의 장치를 연결하는 기술
        - 공기에 주파수를 쏘아 무선 통신망을 구축, 2.4GHz 또는 5GHz 대역 중 하나를 사용
        - 5GHz 대역은 사용할 수 있는 채널 수도 많고 동시에 사용할 수 있기 때문에 상대적으로 깨끗한 전파환경을 구축이 가능하여 해당 대역을 사용

        와이파이 : 전자기기들이 무선 LAN 신호에 연결할 수 있게하는 기술
        BSS : 기본 서비스의 집합, 동일 BSS 내에 있는 AP들과 장치들이 서로 통신이 가능한 구조
            - 근거리 무선 통신을 제공
            - 하나의 AP만을 기반으로 구성되어 있어 사용자가 한 곳에서 다른 곳으로 자유롭게 이동하며 네트워트를 접속하는 것은 불가

        ESS : 하나 이상의 연결된 BSS 그룹
            - 장거리 무선 통신을 제공
            - BSS 보다 더 많은 가용성과 이동성을 지원(다른 장소로 이동해도 중단 없이 네크워크에 계속 연결 가능)


### 계층 간 데이터 송수신 과정

    클라이언트가 컴퓨터를 통해 다른 컴퓨터로 데이터를 요청하면 애플리케이션 계층에서 전송 계층으로 클라이언트가 보내는 요청 값들이 '캡슐화 과정'을 거쳐 전달되고
    다시 링크 계층을 통해 해당 서버와 통신을 하고 해당 서버의 링크 계층으로부터 애플리케이션까지 '비캡슐화 과정'을 거쳐 데이터가 전송된다.

    - 캡슐화 과정(상위계층 => 하위계층)
        - 상위 계층의 헤더와 데이터를 하위 계층의 데이터 부분에 포함시켜 해당 계층의 헤더를 삽입하는 과정
        - 애플리케이션 계층의 데이터가 전송 계층으로 전달되면서 '세그먼트' 또는 '데이터그램'화 되며 TCP(L4) 헤더가 붙여진다
        - 그리고 이후 인터넷 계층으로 가면서 IP(L3)헤더가 붙여지게 되며 '패킷'화가 되고
        - 이후 링크 계층으로 전달되면서 프레임 헤더와 프레임 트레일러가 붙어 '프레임'화가 된다

    - 비캡슐화 과정(하위계층 => 상위계층)
        - 하위계층에서 상위계층으로 가며 각 계층의 헤더 부분을 제거하는 과정
        - 캡슐화된 데이터를 받게 되면 링크 계층에서부터 타고 올라오면서 프레임화된 데이터를 다시 패킷화를 거쳐 세그먼트, 데이터그램화를 거쳐 메시지화가 된다
        - 그 이후 최종적으로 사용자에게 애플리케이션의 PDU인 메시지로 전달


## 2.2.2 PDU

    - 네트워크의 어떠란 계층에서 계층으로 데이터가 전달될 때 한 덩어리의 단위를 PDU(Protocol Data Unit)라고 한다
    - PDU는 제어 관련 정보들이 포함된 페이로드('헤더', 데이터)로 구성되어 있으면 계층마다 부르는 명칭이 다르다
        - 애플리케이션 계층 : 메시지
        - 전송계층 : 세그먼트(TCP), 데이터그램(UDP)
        - 인터넷 계층 : 패킷
        - 링크 계층 : 프레임(데이터 링크 계층), 비트(물리 계층)


# 2.3 네트워크 기기

    네크워크는 여러 개의 네트워크 기기를 기반으로 구축


## 2.3.1 네트워크 기기의 처리 범위


    - 네트워크 기기는 계층별로 처리 범위를 나눌 수 있다
    - 상위 계층을 처리하는 기기는 하위 계층을 처리할 수 있으나 그 반대는 불가
        
        - 애플리케이션 계층 : L7 스위치
        - 인터넷 계층 : 라우터, L3 스위치
        - 데이터 링크 계층 : L2 스위치, 브리지
        - 물리계층 : NIC, 리피터, AP


## 2.3.2 애플리케이션 걔층을 처리하는 기기

    - 스위치 : 여러 장비를 연결하고 데이터 통신을 중재하며 목적지가 연결된 포트로만 전기 신호를 보내 데이터를 전송하는 통신 네트워크 장비

    - L7 스위치(=로드밸런서) : 서버의 부하를 분산하는 기기
        - 클라이언트로부터 오는 요청들을 뒤쪽의 여러 서버로 나누는 역할
        - 시스템이 처리할 수 있는 트래픽 증가를 목표
        - URI, 서버, 캐시, 쿠키들을 기반으로 트래픽을 분산
        - 바이러스, 불필요한 외부 데이터 등을 걸러내는 필터링 기능과 응용 프로그램 수준의 트래픽 모니터링도 가능
        - 만약 장애가 발생한 서버가 있을 경우 트래픽 분산 대상에서 제외해야 하는데, 이는 정기적으로 '헬스 체크(health check)'를 이용하여 감시

        * L4 스위치와 L7 스위치의 차이 
            - 로드밸런서로는 L7 스위치뿐만 아니라 L4 스위치도 있다.
            - L4 스위치는 전송 계층을 처리하는 기기로 메세지를 기반으로 인식하지 못하고 IP와 포트를 기반으로 트래픽을 분산
              (반면 L7 로드밸런서는 IP, 포트 외에도 URL, HTTP 헤더, 쿠키 등을 기반으로 트래픽을 분산)

        * 헬스 체크(health check)
            - L4 스위치 또는 L7 스위치 모두 헬스 체크를 통해 정상적인 서버 또는 비정상적인 서버를 판별
            - 전송 주기와 재전송 횟수 등을 설정한 이후 반복적으로 서버에 요청을 보낸다
            - 이때 서버에 부하가 되지 않을 만큼 요청 횟수가 적절해야 하며 TCP, HTTP 등 다양한 방법으로 요청을 보내며 정상적으로 요청이 이루어지면 정상적인 서버로 판별

        * 로드밸런서를 이용한 서버 이중화
            - 로드밸런서는 대표적인 기능으로 서버 이중화를 들 수 있는데 서비스를 안정적으로 운용하기 위해서는 2대 이상의 서버는 필수적
            - 2대 이상의 서버를 기반으로 가상 IP를 제공하고 이를 기반으로 안정적인 서비스를 제공


## 2.3.3 인터넷 계층을 처리하는 기기(라우터, L3 스위치)

    - 라우터(router)
        - 여러 개의 네트워크를 연결, 분할, 구분시켜주는 역할
        - "다른 네트워크에 존재하는 장치끼리 서로 데이터를 주고받을 때 패킷 소모를 최소화하고 경로를 최적화하여 최소 경로로 패킷을 포워딩"하는 장비

    - L3 스위치
        - L2 스위치의 기능과 라우팅 기능을 갖춘 장비
        - L3 스위치를 라우터라고 해도 무방한데, 하드웨어 기반의 라우팅을 담당하는 장치를 L3 스위치라고 한다


## 2.3.4 데이터 링크 계층을 처리하는 기기(L2 스위치, 브리지)

    - L2 스위치
        - 장치들의 MAC 주소를 MAC 주소 테이블을 통해 관리
        - 연결된 장치로부터 패킷이 왔을 때 패킷 전송을 담당
        - IP 주소를 이해하지 못해 단순히 패킷의 MAC 주소를 읽어 스위칭하는 역할
        - 목적지가 MAC 주소 테이블에 없다면 전체 포트에 전달하고 MAC 주소 테이블의 주소는 일정 시간 이후 삭제

    - 브리지
        - 두 개의 근거리 통신망(LAN)을 상호 접속할 수 있도록 하는 통신망 연결 장치
        - 장치에서 받아온 MAC 주소를 MAC 주소 테이블로 관리
        - 통신망의 범위를 확장하고 서로 다른 LAN 등으로 이루어진 '하나의' 통신망을 구축할 때 사용

    
## 2.3.5 물리 계층을 처리하는 기기(NIC, 리피터, AP)

    - NIC(Network Interface Card)
        - LAN 카드라고 하는 네트워크 인터페이스 카드는 2대 이상의 컴퓨터 네트워크를 구성하는데 사용
        - 네크워트와 빠른 속도로 데이터를 송수신하도록 컴퓨터 내에 설치하는 확장 카드
        - 고유의 식별번호인 MAC 주소가 있다

    - 리피터
        - 들어오는 약해진 신호 정도를 증폭하여 다른 쪽으로 전달하는 장치
    
    - AP(Access Point)
        - 패킷을 복사하는 기기
        - AP에 유선 LAN을 연결한 후 다른 장치에서 무선 LAN 기술(와이파이 등)을 사용하여 무선 네트워크 연결 가능


# 2.4 IP 주소

## 2.4.1 ARP

    - 컴퓨터와 컴퓨터 간의 통신은 IP 주소에서 ARP를 통해 MAC 주소를 찾아 MAC 주소를 기반으로 통신한다
    - ARP(Address Resolution Protocol)은 IP와 MAC 주소의 다리 역할을 하는 프로토콜
    - ARP를 통해 가상 주소인 IP 주소를 실제 주소인 MAC 주소로 변환
    - 이와 반대로 RARP를 통해 실제 주소인 MAC 주소를 가장 주소인 IP 주소로 변환

    예) 장치 A가 ARP Request 브로드캐스트를 보내서 IP 주소인 120.70.80.3에 해당하는 
    MAC 주소를 찾고 해당 주소에 맞는 장치 B가 ARP Replay 유니캐스트를 통해 MAC 주소를 반환하는 과정

    용어
    - 브로드캐스트 : 송신 호스트가 전송한 데이터가 네트워크에 연결된 모든 호스트에 전송되는 방식
    - 유니캐스트 : 고유 주소로 식별된 하나의 네트워크 목적지에 1:1로 데이터를 전송하는 방식


# 2.4.2 홉바이홉 통신

    - 통신 장치에 있는 '라우팅 테이블'의 IP를 통해 시작 주소부터 시작하여 다음 IP로 계속해서 이동하는 '라우팅' 과정을 거쳐 패킷이 최종 목적지까지 도달하는 통신

    용어
    - 라우팅 : IP 주소를 찾아가는 과정
    - 라우팅 테이블 : 송신지에서 수신지까지 도달하기 위해 사용되며 라우터에 들어가 있는 목적지 정보들과 그 목적지로 가기 위한 방법이 들어있는 리스트
    - 게이트웨이 : 서로 다른 통신망, 프로토콜을 사용하는 네트워크 간의 통신을 가능(서로 다른 네크워크상의 통신 프로토콜을 변환)하게 하는 관문 역할을 하는 컴퓨터나 소프트웨어
    - 프로토콜 : 컴퓨터 내부에서, 또는 컴퓨터 사이에서 데이터의 교환 방식을 정의하는 규칙 체계


# 2.4.3 IP 주소 체계

    - IP 주소는 IPv4와 IPv6로 나뉜다
    - IPv4는 32비트를 8비트 단위로 점을 찍어 표기(123.45.67.89)
    - IPv6는 64비트를 16비트 단위로 점을 찍어 표기(2001:db8::ff00:42:8329)

    클래스 기반 할당방식
        - IP 주소 체계는 과거를 거터 발전해오고 있으며 처음에는 A, B, C, D, E 다섯 개의 클래스로 구분하는 클래스 기반 할당 방식을 사용
        - 앞의 부분을 '네트워크 주소', 그 뒤에 있는 부분을 컴퓨터에 부여하는 주소인 '호스트 주소'로 놓아서 사용
        - 클래스 A • B • C는 일대일 통신으로 사용되고 클래스 D는 멀티캐스트 통신 클래스 E는 앞으로 사용할 예비용으로 사용
        - 네크워크의 첫 번째 주소는 네트워크 주소로 사용되고 가장 마지막 주소는 브로드캐스트용 주소로 네트워크에 속해 있는 모든 컴퓨터에 데이터를 보낼 때 사용
        - 예를 들어 클래스 A로 12.0.0.0 이란 네트워크를 부여받았을 때, 12.0.0.1 ~ 12.255.255.254의 호스트 주소를 부여받은 것인데 
          이때 첫 번째 주소인 12.0.0.0은 네트워크 구별 주소로 사용하면 안 되고 가장 마지막 주소인 12.255.255.255의 경우 브로드캐스트용으로 남겨둬야 하여 이 또한 사용하면 안됨
        - 그렇기 때문에 그 사이의 12.0.0.1 ~ 12.255.255.254를 컴퓨터에 부여할 수 있는 호스트 주소로 사용할 수 있다.
        - 하지만 이 방식은 사용하는 주소보다 버리는 주소가 많은 단점이 있다

    DHCP(Dynamic Host Configuration Protocol)
        - IP 주소 및 기타 통신 매개변수를 자동으로 할당하기 위한 네트워크 프로토콜
        - 인터넷에 접속할 때마다 자동으로 IP 주소를 할당
        - 많은 라우터와 게이트웨이 장비에 DHCP 기능이 있으며 이를 통해 가정용 네트워크에서 IP 주소를 할당

    NAT(Network Address Translation)
        - 패킷이 라우팅 장치를 통해 전송되는 동안 패킷의 IP 주소 정보를 수정하여 IP 주소를 다른 주소로 매핑하는 방법
        - NAT로 공인 IP와 사설 IP로 나눠서 많은 주소를 처리
        - NAT를 가능하게 하는 소프트웨어는 ICS, RRAS, Netfilter 등이 있다.

        NAT를 이용한 보안
            - 내부 네트워크에서 사용하는 IP 주소와 외부에 드러나는 IP 주소를 다르게 유지할 수 있어 내부 네트워크에 대한 보안이 가능해진다
        
        NAT의 단점
            - 호스트 숫자에 따라서 접속 속도가 느려질 수 있다


# 2.5 HTTP

    HTTP는 애플리케이션 계층으로서 웹 서비스 통신에 사용됨


## 2.5.1 HTTP/1.0

    - 한 연결당 하나의 요청을 처리하도록 설계되어 있다, 이는 RTT의 증가를 불러온다
    - 서버로부터 파일을 가져올 때마다 TCP의 3-웨이 핸드셰이크를 계속해서 열어야 하기 때문에 RTT가 증가하는 단점이 있다

    용어
    RTT : 패킷이 목적지에 도달하고 나서 다시 출발지로 돌아오기까지 걸리는 시간(=패킷 왕복시간)

    RTT의 증가를 해결하기 위한 방법(이미지 스플리팅, 코드 압축, 이미지 Base64 인코딩)

    - 이미지 스플리팅
        - 많은 이미지를 다운받게되면 과부하가 걸리므로 이미지가 합쳐 있는 하나의 이미지를 다운받고 이를 기반으로 background-image의 position을 이용하여 이미지를 표기

    - 코드 압축
        - 코드를 압축해서 개행 문자, 빈칸을 없애서 코드의 크기를 최소화하는 방법

    - 이미지 Base64 인코딩
        - 이미지 파일을 64진법으로 이루어진 문자열로 인코딩하는 방법
        - 서버와 연결을 열고 이미지에 대해 서버에 HTTP 요청을 할 필요가 없다는 장점이 있다
        - 하지만 Base64 문자열로 반환할 경우 37% 정도 크기가 더 커지는 단점이 있다.

    용어
    인코딩 : 정보의 형태나 형식을 표준화, 보안, 처리 속도 향상, 저장 공간 절약 등을 위해 다른 형태나 형식으로 변환하는 방식


## 2.5.2 HTTP/1.1

    - 매번 TCP 연결을 하는 것이 아니라 한 번 TCP 초기화를 한 이후에 keep-alive라는 옵션으로 여러 개의 파일을 송수신할 수 있게 변경
    - HTTP/1.0 에서도 같은 옵션이 있어지만 HTTP/1.1부터 표준화되어 기본 옵션으로 설정됨
    - 한번 TCP 3-웨이 핸드셰이크가 발생하면 그다음부터 발생하지 않지만 문서 안에 포함된 다수의 리소스(이미지, 동영상, CSS, JS 등)을 처리하려면 요청할 리소스 개수레 비례해서 대기 시간이 길어진다는 단점이 있다.

    HOL Blocking(Head Of Line Blocking)
        - 네트워크에서 같은 큐에 있는 패킷이 그 첫 번째 패킷에 의해 지연될 때 발생하는 성능 저하 현상
        - 예를 들어 image.jpg 와 style.css, data.xml을 다운로드받을 때 보통은 순차적으로 잘 받아지지만 image.jpg가 느리게 받아진다면 그 뒤에 있는 것들이 대기하게 되며 다운로드가 지연되는 상태를 말한다.

    무거운 헤더 구조
        - HTTP/1.1의 헤더에는 쿠키 등 많은 메타데이터가 들어 있고 압축이 되지 않아 무겁다


## 2.5.3 HTTP/2

    HTTP/2는 SPDY 프로토콜에서 파생된 HTTP/1.x 보다 지연 시간을 줄이고 응답 시간을 더 빠르게 할 수 있으며 멀티플렉싱, 헤더 압축, 서버 푸시, 요청의 우선순위 처리를 지원

    멀티플렉싱
        - 여러 개의 스트림을 사용하여 송수신하는 것
        - 이를 통해 특정 스트림의 패킷이 손실되었다고 하더라도 해당 스트림에만 영향을 미치고 나머지 스트림은 멀쩡히 동작
        - 병렬적인 스트림들을 통해 서빙하고 스트림 내의 데이터들도 쪼개져 있다
        - 애플리케이션에서 받아온 메시지를 독립된 프레임으로 조각내어 서로 송수신한 이루 다시 조립하며 데이터를 주고받는다
        - 이를 통해 단일 연결을 사용하여 병렬로 여러 요청을 받을 수 있고 응답을 줄일 수 있다(HOL Blocking 해결 가능)

    용어
    스트림 : 시간이 지남에 따라 사용할 수 있게 되는 일련의 데이터 요소를 가리키는 데이터 흐름

    헤더 압축
        - HTTP/1.x는 크기가 큰 헤더라는 문제가 있었는데 HTTP/2는 헤더 압축을 써서 이를 해결, 이때 허프만 코딩 압축 알고리즘을 사용하는 HPACK 압축 형식을 가진다

        허프만 코딩
            - 문자열을 문자 단위로 쪼개 빈도수를 세어 빈도가 높은 정보는 적은 비트 수를 사용, 빈도가 낮은 정보는 비트 수를 많이 사용하여 표현해서 전체 데이터의 표현에 필요한 비트양을 줄이는 원리

    서버 푸시
        - HTTP/1.1와 달리 HTTP/2는 클라이언트 요청 없이 서버가 바로 리소스를 푸시할 수 있다
        - html에는 css나 js 파일이 포함되기 마련인데 html을 읽으면서 그 안에 들어 있던 css 파일을 서버에서 푸시하여 클라이언트에 먼저 줄 수 있다


## 2.5.4 HTTPS(통신의 암호화)

    HTTP/2는 HTTPS 위에서 동작, HTTPS는 애플리케이션 계층과 전송 계층 사이에 신뢰계층인 SSL/TLS 계층을 넣은 신뢰할 수 있는 HTTP 요청을 말한다

    SSL/TLS
        - 전송 계층에서 보안을 제공하는 프로토콜
        - 클라이언트와 서버가 통신할 때 SSL/TLS를 통해 제 3자가 메시지를 도청하거나 변조하지 못하도록 한다
        - SSL/TLS를 통해 공격자가 서버인 척하며 사용자 정보를 가로채는 네트워크상의 '인터셉터'를 방지할 수 있다
        - 보안 세션을 기반으로 데이터를 암호화하면 보안 세션이 만들어질 때 인증 메커니즘, 키 교환 암호화 알고리즘, 해싱 알고리즘이 사용된다

        보안 세션
            - 보안이 시작되고 끝나느 동안 유지되는 세션, SSL/TLS는 핸드셰이크를 통해 보안 세션을 생성하고 이를 기반으로 상태 정보 등을 공유
            - 클라이언트와 서버와 키를 공유하고 이를 기반으로 인증, 인증 확인 등의 작업이 일어나느 단 한 번의 1-RTT가 생긴 후 데이터를 송수신하는데 클라이언트에서 사이퍼 슈트를 서버에 전달하면 서버는 받은 사이퍼 슈트의 암호화 알고리즘 리스트를 제공할 수 있는 확인, 제공할 수 있다면 서버에서 클라이언트로 인증서를 보내는 인증 메커니즘이 시작되고 이후 해싱 알고리즘 등으로 암호화된 데이터의 송수신이 시작된다

            사이퍼 슈트
                - 프로토콜, AEAD 사이퍼 모드, 해싱 알고리즘이 나열된 규약이며 다섯 개가 있다
                    - TLS_AES_128_GCM_SHA256
                    - TLS_AES_256_GCM_SHA384
                    - TLS_CHACHA20_POLY1305_SHA256
                    - TLS_AES_128_CCM_SHA256
                    - TLS_AES_128_CCM_8_SHA256

            AEAD 사이퍼 모드
                - AEAD(Authenticated Encryption with Associated Data)는 데이터 암호화 알고리즘이며 AES_128_GCM 등이 있다
                - 예를 들어 AES_128_GCM이라는 것은 128비트의 키를 사용하는 표준 블록 암호화 기술과 병렬 계산에 용이한 암호화 알고리즘 GCM이 결합된 알고리즘을 뜻한다

        인증 메커니즘
            - 인증 메커니즘은 CA(Certificate Authorities)에서 발급한 인증서를 기반으로 이루어진다
            - CA에서 발급한 인증서는 안전한 연결을 시작하는 데 있어 필요한 '공개키'를 클라이언트에 제공하고 사용자가 접속한 '서버다 신뢰'할 수 있는 서버임을 보장
            - 인증서는 서비스 정보, 공개키, 지문, 디지털 서명 등으로 이루어진다
            - CA는 신뢰성이 엄격하게 공인된 기업들만 참여할 수 있다

            CA 발급 과정
                - 자신의 사이트 정보와 공개키를 CA에 제출하고 이후 CA는 공개키를 해시한 값인 지문을 사용하는 CA의 비밀키 등을 기반으로 CA 인증서를 발급

        암호화 알고리즘
            - 키 교환 알고리즘으로는 대수곡선 기반의 ECDHE 또는 모듈식 기반의 DHE를 사용
            - 둘 다 디피-헬만 방식을 근가으로 만들어짐

            디피-헬만 키 교환 암호화 알고리즘
                - 암호화 알고리즘은 암호키를 교환하는 하나의 방법
                - 공개된 값을 공유하고 각자의 비밀 값과 혼합한 후 혼합 값을 공유한 다음 각자의 비밀 값과 또 혼합한다, 그 이후에 공통의 암호키인 PSK가 생성

        해싱 알고리즘
            - 데이터를 추정하기 힘든 더 작고 섞여 있는 조각으로 만드는 알고리즘
            - SSL/TLS는 해싱 알고리즘으로 SHA-256 과 SHA-384 알고리즘을 사용

            SHA-256 알고리즘
                - 해시 함수의 결과값이 256 비트인 알고리즘으로 해싱을 해야 할 메시지에 1을 추가하는 등 전처리를 하고 전처리된 메시지를 기반으로 해시를 반환

            용어
            해시 : 다양한 길이를 가진 데이터를 고정된 길이를 가진 데이터로 매핑한 값
            해싱 : 임의의 데이터를 해시로 바꿔주는 일이며 해시 함수가 이를 담당
            해시 함수 : 임의의 데이터를 입력으로 받아 일정한 길이의 데이터로 바꿔주는 함수

    SEO에도 도움이 되는 HTTPS
        - 구글은 SSL 인증서를 강조해왔고 사이트 내 모든 요소가 동일할 경우 HTTPS 서비스를 하는 사이트가 그렇지 않은 사이트보다 SEO 순위가 높다고 밝힘
        - SEO 는 검색엔진 최적화로 사용자들이 구글, 네이버 같은 검색엔진으로 웹 사이트를 검색했을 때 그 결과를 페이지 상단에 노출시켜 많은 사람이 볼 수 있도록 최적화하는 방법
        - 서비스를 운영할 경우 SEO 관리는 필수로 이를 위한 방법으로 캐노니컬 설정, 메타 설정, 페이지 속도 개선, 사이트맵 관리 등이 있다

        캐노니컬 설정
            - <link rel="canonical" href="https://example.com/page2.php" />
            - 사이트 link에 캐노니컬 설정을 해야한다

        메타 설정
            - html 파일의 가장 윗부분인 메타를 잘 설정해야 한다

        페이지 속도 개선
            - PageSpeedinsights로 가서 자신의 서비스에 대한 리포팅을 주기적으로 받으며 관리해야 한다

        사이트맵 관리
            - 사이트맵(sitemap.xml)을 정기적으로 관리
            - 사이트맵 제네레이터를 사용하거나 직접 코드를 만들어 구축해도 된다

            HTML과 XML의 차이
                1) HTML의 용도는 데이터를 표시, XML은 데이터를 저장 및 전송
                2) HTML에는 미리 정의된 태그가 있지만 사용자는 XML에서 고유한 태그를 만들고 정의가 가능
                3) XML은 대/소문자를 구별하여 <book>을 <Book>으로 태그를 작성하면 구문 분석기에서 오류가 발행, HTML은 구분하지 않는다

            JSON과 XML의 차이
                1) XML은 JSON과 비교했을 때 닫힌 태그가 계속해서 들어가기 때문에 JSON과 비교하면 무겁다
                2) 또한 JavaScript Object로 변환하기 위해서 JSON 보다는 더 많은 노력이 필요

    HTTPS 구축 방법
        - 직접 CA 에서 구매한 인증키를 기반으로 HTTPS 서비스를 구축
        - 서버 앞단의 HTTPS를 제공하는 로드밸런스를 둔다
        - 서버 앞단의 HTTPS를 제공하는 CDN를 둔다

## 2.5.5 HTTP/3

    - TCP 위에서 돌아가는 HTTP/2와 달리 QUIC이라는 계층 위에서 돌아가며, TCP 기반이 아닌 UDP 기반으로 돌아간다
    - 또한, HTTP/2에서 장점이었던 멀티플렉싱을 가지고 있으며 초기 연결 설정 시 지연 시간 감소라는 장점이 있다

    초기 연결 설정 시 지연 시간 감소
        - QUIC은 TCP를 사용하지 않기 때문에 통신을 시작할 때 3-웨이 핸드셰이크 과정을 거치지 않아도 된다
        - QUIC은 첫 연결 설정에 1-RTT만 소요, 클라이언트가 서버에 어떤 신호를 한 번 주고, 서버도 거기에 응답하기만 하면 바로 본 통신을 시작


## www.naver.com을 주소창에 입력하면 어떻게 될까?

    - 리다이렉트, 캐싱, DNS, IP 라우팅, TCP 연결 구축을 거쳐 요청, 응답이 일어나는 TTFB(Time ro First Byte)가 시작, 이후 컨텐트를 다운받게되고 이후 브라우저 렌더링 과정을 거쳐 네이버로 가는 화면이 나타난다
    
        1) 리다이렉트
            리다이렉트가 있다면 리다이렉트를 진행, 없다면 그대로 해당 요청에 대한 과정 진행
        
        2) 캐싱 
            - 해당 요청이 캐싱이 가능한지 그렇지 않은지를 파악, 캐싱이 이미 된 요청이라면 그 다음 단계로 넘어간다(캐싱은 요청된 값의 결과값을 저장하고 그 값을 다시 요청하면 다시 제공하는 기술)
            - 이는 브라우저 캐시와 공유 캐시로 나뉘어진다
                - 브라우저 캐시 : 쿠키, 로컬스토리지 등을 포함한 캐시, 개인캐시라고도 하며 브라우저 자체가 사용자가 HTTP를 통해 다운로드하는 모든 무서를 보유하는 것
                - 공유 캐시 : 클라이언트와 서버 사이(프록시서버)에 있으며 사용자간에 공유할 수 있는 응답을 저장할 수 있다, 대표적인 예로 요청한 서버 앞단에 프록시서버가 캐싱을 하는 것을 말하며, 이를 리버스 프록시를 둬서 내부서버로 포워드한다고도 말한다

        3) DNS(Domain Name System)
            - 계층적인 도메인 구조와 분산된 데이터베이스를 이용한 시스템으로 FQDN을 인터넷 프로토콜인 IP로 바꿔주는 시스템
            - 이는 DNS 관련 요청을 네임서버로 전달하고 해당 응답값을 클라이언트에게 전달하는 리졸버, 도메인을 IP로 변환하는 네임서버 등으로 이루어져 있다
            - 예를 들어 www.naver.com 에 DNS 쿼리가 오면 오른쪽부터 역순으로 [Root DNS] > [.com DNS] > [.naver DNS] > [.www DNS] 과정을 거쳐 완벽한 주소를 찾아 IP 주소를 매핑 
            - 참고 : FQDN(Fully Qualified Domain Name : 호스트와 도메인이 합쳐진 완전한 도메인 이름, www 등은 호스트 부분, naver.com 은 도메인이라고 한다)
                - www = host 주소 또는 Third level 도메인, sub 도메인이라고 불림
                - naver = second level 도메인
                - com = top level 도메인

        4) IP 라우팅
            - 해당 IP를 기반으로 라우팅, ARP 과정을 거쳐 실제 서비스를 찾음

        5) TCP 연결 구축
            - 브라우저가 TCP 3웨이-핸드셰이크 및 SSL 연결 등을 통해 연결을 설정
            - 이후 요청을 보낸 후 해당 요청한 서버로 부터 응답을 받는다
            - TCP 연결은 HTTP/2 까지 일어나고 HTTP/3는 TCP 연결이 아닌 QUIC 연결이 일어난다
            
        6) 콘텐츠 다운로드
            - 요청한 컨텐츠를 서버로부터 다운

        7) 브라우저렌더링
            - 받은 데이터를 바탕으로 브라우저 엔진이 브라우저렌더링 과정을 거쳐 화면을 만든다